本文以问答的方式来看一看操作系统的知识领域里，一般需要关注什么问题。

#  1. 操作系统基础
## 1.1 什么是操作系统？

+ 1. 操作系统（Operating System，简称OS）是管理计算机硬件与软件资源的程序，是计算机系统的内核与基石；
+ 2. 操作系统本质上是运行在计算机上的软件程序 ；
+ 3. 操作系统为用户提供一个与系统交互的操作界面 ；
+ 4. 操作系统分内核与外壳（我们可以把外壳理解成围绕着内核的应用程序，而内核可以理解为能直接操作硬件的程序）。


关于内核多插一嘴：
内核负责管理系统的进程、内存、设备驱动程序、文件和网络系统等等，决定着系统的性能和稳定性。是连接应用程序和硬件的桥梁。内核就是操作系统背后黑盒的核心。  

<img src="https://github.com/lowkeyway/Embedded/blob/master/Software/OS/Pic/00_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E6%A0%B8%E5%92%8C%E5%A4%96%E5%A3%B3.png">  

## 1.2 系统调用

介绍系统调用之前，我们先来了解一下用户态和系统态。  
根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：  
+ 1. 用户态(user mode) : 用户态运行的进程或可以直接读取用户程序的数据。
+ 2. 系统态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。  

说了用户态和系统态之后，那么什么是系统调用呢？  

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！  

也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。  

这些系统调用按功能大致可分为如下几类：
+ 设备管理。完成设备的请求或释放，以及设备启动等功能。
+ 文件管理。完成文件的读、写、创建及删除等功能。  
+ 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
+ 进程通信。完成进程之间的消息传递或信号传递等功能。
+ 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

# 2 进程和线程[参考](https://blog.csdn.net/u012218309/article/details/81912074)

首先明确一点，linux对进程和线程不做区分，统一由task_struct来管理所有进程和线程。  
那么如何在linux下区分进程和线程呢？  

## 2.1 为什么要引入线程的概念？

一个进程包含很多系统资源：进程控制块、虚存空间、文件系统，文件I/O、信号处理函数，创建一个进程的过程就是这些资源被创建的过程。  

系统调用fork创建一个进程时子进程是一段独立的内存空间，其中的资源是父进程资源的副本，两个进程是完全独立不共享内存资源的，二者需要通过IPC进行通信。  

这样的做法在有些场景下并不是高效的做法，例如：比如某进程fork出一个子进程后，其子进程仅仅是为了调用exec执行另一个执行文件，那么在fork过程中对于内存空间的复制就是多余的；再例如：如果通过这种方式处理并行计算问题，那么就得在不同cpu创建不同的进程，然后通过IPC再把计算结果汇总，这样做的开销往往足以抵消并行计算带来的好处。  

另外，进程是系统中程序执行和资源分配的基本单元，每个进程都拥有自己的数据段、代码段和堆栈段，进程进行切换时都会伴随着上下文的切换，这也会带来开销。  

所以把计算单元抽象到进程上是不充分的，这也就是许多系统中都引入了线程的概念的原因。  

## 2.2 Linux怎么创建进程？  

Linux创建进程一共有三种方式：fork  vfork  clone。三个函数分别通过sys_fork()、sys_vfork()和sys_clone()调用do_fork()去做具体的创建工作，只不过传入的参数不同。  

** sys_fork()： **
```
asmlinkage long sys_fork(struct pt_regs regs)
 
{
 
    return do_fork(SIGCHLD, regs.rsp, &regs, 0);
 
}
```
传入的参数SIGCHLD表示在子进程终止后将发送信号SIGCHLD信号通知父进程。


** sys_vfork()： **
```
asmlinkage long sys_vfork(struct pt_regs regs)
 
{
 
    return do_fork(CLONE_VFORK | CLONE_VM | SIGCHLD, regs.rsp, &regs, 0);
 
}
```

** sys_clone()： **
```
casmlinkage int sys_clone(struct pt_regs regs)
 
{
 
    unsigned long clone_flags;
 
    unsigned long newsp;
 
 
 
    clone_flags = regs.ebx;
 
    newsp = regs.ecx;
 
    if (!newsp)
 
        newsp = regs.esp;
 
    return do_fork(clone_flags, newsp, &regs, 0);
 
}
```

## Linux怎么创建线程？

为了方便移植，linux使用POSIX标准创建线程，在linux2.6之前使用linux Thread库实现多线程，从linux2.6开始，都是使用NPLT库来实现线程的创建。这两个库都是使用pthread_create()来创建线程。  

抛开网上一大堆所谓的轻量级进程LWP，那些都过时了，都是2.6版本以前提出的概念，从2.6开始的多线程不需要理解这个LWP，只需要知道如果使用clone创建的进程与父进程共享内存空间则认为它是线程。  


<img src="https://github.com/lowkeyway/Embedded/blob/master/Software/OS/Pic/01_NPLT%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%88%9B%E5%BB%BA.png">

上图中，红色线以上是用户态，下面是内核态。左边虚线框内是单线程的，右边是多线程。 

NPLT创建的线程属于“一对一”模型，为什么叫一对一？因为调用pthread_create()时会在用户空间创建一个线程同时也会在内核空间创建与之对应的线程。  

用户空间的线程 - - 负责执行线程的创建、销毁等操作  

内核空间的线程 - - 负责调度  

### 1 - pthread_create

pthread_create是创建线程的入口，主要参数是一个函数指针，其指向的函数为线程创建成功后要执行的函数。由于线程组中的各个线程是可以并行运行在不同的CPU上的，所以各个线程必须得有自己独立的用户态栈和内核栈。Linux用户态栈的大小一般是8M，通过mmap在MemoryMapping Area中分配一块内存（不考虑用户态栈缓存）。在用户态也有一个数据结构用来描述线程（structpthread），该数据结构就放在用户态栈的最下面的位置，其中会存放线程创建成功后要执行的函数地址。

分配完structpthread和用户态栈之后（其实还有很多事情，不过都是些琐事），差不多就可以带着这些信息进入内核申请task_struct了。

### 2 - clone

像创建新的进程这种资源管理工作基本上都要通过内核完成，从用户态进入内核态时，都会把进程在用户态时的状态保存在内核栈中，这样完成了内核态的任务之后返回时可以恢复用户态的状态。

glibc在用户态对clone封装了一层，名为ARCH_CLONE。其中会把线程创建成功后要执行的函数地址以及参数压入用户态栈，然后再调用系统调用clone，这样系统调用clone返回后再从栈中取出线程函数以及对应的参数，继而开始执行线程函数。

系统调用（syscall）clone用于创建当前进程的一个副本，fork就是调用的clone。我们这里是要创建线程，那么对clone的用法当然与fork有所区别了。区别主要在于clone的参数clone_flags的设置：  
**创建线程调用的clone：**  

<img src="https://github.com/lowkeyway/Embedded/blob/master/Software/OS/Pic/02_%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E8%B0%83%E7%94%A8clone%E7%9A%84Flag.jfif">

**创建进程调用的clone:**  

<img src="https://github.com/lowkeyway/Embedded/blob/master/Software/OS/Pic/03_%E5%88%9B%E5%BB%BA%E8%BF%9B%E7%A8%8B%E8%B0%83%E7%94%A8%E7%9A%84clone.jfif">
 
可以看到创建线程时使用的clone_flags中多了CLONE_VM、CLONE_FS、CLONE_FILES和CLONE_SIGNAL（CLONE_SIGHAND| CLONE_THREAD），这些是实现Posixthread规范的关键。这些参数体现在NPLT线程在内核中的数据模型图中就是其中的mm、fs、files、signal、sighand和pending字段指向相同的对象。正因为这些数据的共享，线程间的数据共享和同步比在进程间简单得多。
 
**NPLT线程在内核中的数据模型图**

<img src="https://github.com/lowkeyway/Embedded/blob/master/Software/OS/Pic/04_NPLT%E7%BA%BF%E7%A8%8B%E5%9C%A8%E5%86%85%E6%A0%B8%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%9B%BE.jfif">
 
 不管是通过fork产生的进程还是通过pthread_create产生的线程，其在内核中都对应着一个task_struct，linux_structure图中有两个task_struct，其中右边的task_struct是通过pthread_create产生的，因此左边的task_struct是threadgroup的leader。task_struct有很多字段，其中mm就是用来描述虚拟地址空间的。我们可以看到两个task_struct的mm指向了同一个mm_struct对象，也就是前面提到的线程间共享同一个虚拟地址空间。
 
 
 用户态中，多线程会作为一个进程看待，在内核中，会被抽象为“线程组”。线程组中的task_struct有不同的pid字段，但是会有相同的tgid(threadgroup id)字段，这个tgid作为用户态进程的pid给上层使用。所以，在一个进程下的每个线程中获取到的pid是相同的，用户态的pid与内核态的pid不是同一个东西，想获取线程在内核态的pid可以通过系统调用（gettid）来获取。线程组中的task_struct会通过一个链表（thread_group）链接起来，后面创建的线程的task_struct中的group_leader字段会指向leader。通过共享mm_struct、fs、signal相关的数据，再通过thread_group相关的设置，线程的概念基本就实现了

## 2.3 进程有哪几种状态?

我们一般把进程大致分为 5 种状态，这一点和线程很像！  
+ **创建状态(new)**：进程正在被创建，尚未到就绪状态。
+ **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
+ **运行状态(running)** ：进程正在处理器上上运行(单核CPU下任意时刻只有一个进程处于运行状态)。
+ **阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
+ **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。


## 2.4 进程间的通信方式

大概有 7 种常见的进程间的通信方式。  
+ 1. **管道/匿名管道(Pipes)** ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。
+ 2. **有名管道(Names Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循先进先出(first in first out)。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
+ 3. **信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
+ 4. **消息队列(Message Queuing)** ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比FIFO更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。
+ 5. **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
+ 6. **共享内存(Shared memory)** ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
+ 7. **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

用Linux中的例子来看常用的：

+ **信号(Signal)**: pthread_cond_signal/pthread_cond_wait
+ **消息队列(Message Queuing)**: msgget/msgctl/msgsnd/msgrcv/
+ **信号量(Semaphores)**: semget/semop/semctl
+ **共享内存(Shared memory)**: mmap
+ **套接字(Sockets)**: Netlink

## 2.5 线程间的同步的方式

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：  
+ 1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。  
+ 2. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
+ 3. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操

用Linux中的例子来看常用的：
+ **互斥量(Mutex)**： pthread_mutex_lock/pthread_mutex_unlock
+ **信号量(Semaphores)**: sem_t-sem_wait/sem_post
+ **事件(Event)**： wait_event_interruptible/wake_up

# 3. 操作系统内存管理基础

## 3.1 内存管理介绍

操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。  

## 3.2 常见的几种内存管理机制

简单分为连续分配管理方式和非连续分配管理方式这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 块式管理 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如页式管理 和 段式管理。  

+ **1. 块式管理** ：远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
+ **2. 页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
+ **3. 段式管理** ：页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。段式管理通过段表对应逻辑地址和物理地址。
+ **4. 段页式管理机制** ：段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段页式管理机制 中段与段之间以及段的内部的都是离散的。


## 3.3 快表和多级页表

在分页内存管理中，很重要的两点是：
+ 1. 虚拟地址到物理地址的转换要快
+ 2. 解决虚拟地址空间大，页表也会很大的问题。

### 快表

为了解决虚拟地址到物理地址的转换速度，操作系统在 页表方案 基础之上引入了 快表 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时CPU要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：  

+ 1. 根据虚拟地址中的页号查快表；
+ 2. 如果该页在快表中，直接从快表中读取相应的物理地址；
+ 3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
+ 4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。


看完了之后你会发现快表和我们平时经常在我们开发的系统使用的缓存（比如 Redis）很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。


### 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章：
[多级页表如何节约内存](https://www.polarxiong.com/archives/多级页表如何节约内存.html)

### 总结

为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即TLB）的概念。不论是快表还是多级页表实际上都利用到了程序的局部性原理，局部性原理在后面的虚拟内存这部分会介绍到。


## 3.4 分页机制和分段机制的共同点和区别

+ **共同点**
  + 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
  + 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
 
+ **区别**
  + 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
  + 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。
 
## 3.5 逻辑(虚拟)地址和物理地址

我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

## 3.6 CPU寻址是什么?为什么需要虚拟地址空间?

现代处理器使用的是一种称为 虚拟寻址(Virtual Addressing) 的寻址方式。使用虚拟寻址，CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 内存管理单元（Memory Management Unit, MMU）的硬件。如下图所示：

<img src="https://github.com/lowkeyway/Embedded/blob/master/Software/OS/Pic/05_MMU.png">

### 为什么要有虚拟地址空间呢？

先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，程序都是直接访问和操作的都是物理内存 。但是这样有什么问题呢？

+ 1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。
+ 2. 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个QQ音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址1xxx赋值后，QQ音乐也同样给内存地址1xxx赋值，那么QQ音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。

通过虚拟地址访问内存有以下优势：
+ 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
+ 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
+ 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

# 四 虚拟内存

## 4.1 什么是虚拟内存(Virtual Memory)?

这个在我们平时使用电脑特别是 Windows 系统的时候太常见了。很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。为什么可以这样呢？ 正是因为 虚拟内存 的存在，通过 虚拟内存 可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。这样会更加有效地管理内存并减少出错。  

虚拟内存是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，并且 把内存扩展到硬盘空间。推荐阅读：《虚拟内存的那点事儿》  

维基百科中有几句话是这样介绍虚拟内存的。

+ 虚拟内存 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。From:https://zh.wikipedia.org/wiki/虚拟内存

## 4.2 局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。  

早在1968年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。  

局部性原理表现在以下两个方面：  
+ 1. 时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
+ 2. 空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。  

## 4.3 虚拟存储器

基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——虚拟存储器。  


实际上，我觉得虚拟内存同样是一种时间换空间的策略，你用 CPU 的计算时间，页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。不得不感叹，程序世界几乎不是时间换空间就是空间换时间。  

## 4.4 虚拟内存的技术实现


虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。 虚拟内存的实现有以下三种方式：
+ 1. 请求分页存储管理 ：建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。
+ 2. 请求分段存储管理 ：
+ 3. 请求段页式存储管理 ：


不管是上面那种实现方式，我们一般都需要：
+ 1. 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
+ 2. 缺页中断：如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序；
+ 3. 虚拟地址空间 ：逻辑地址到物理地址的变换。


## 4.5 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断。

+ 缺页中断 就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。在这个时候，被内存映射的文件实际上成了一个分页交换文件。

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

+ OPT页面置换算法（最佳页面置换算法） ：理想情况，不可能实现，一般作为衡量其他置换算法的方法。
+ FIFO页面置换算法（先进先出页面置换算法）  : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
+ LRU页面置换算法（最近未使用页面置换算法） ：LRU（Least Currently Used）算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间T，当须淘汰一个页面时，选择现有页面中其T值最大的，即最近最久未使用的页面予以淘汰。
+ LFU页面置换算法（最少使用页面排序算法） : LFU（Least Frequently Used）算法会让系统维护一个按最近一次访问时间排序的页面链表，链表首节点是最近刚刚使用过的页面，链表尾节点是最久未使用的页面。访问内存时，找到相应页面，并把它移到链表之首。缺页时，置换链表尾节点的页面。也就是说内存内使用越频繁的页面，被保留的时间也相对越长。

https://mp.weixin.qq.com/s/MfLE6TrjlCeH3xT1YSATHg
